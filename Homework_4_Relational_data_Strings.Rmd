---
  title: "BIOS 611 HW4 Relational data (Chapter 13) and Strings (Chapter 14-15)"
  author: "(Your full name here)"
  date: "`r format(Sys.time(), '%m/%d/%Y')`"
  output: html_document
---
  (Due date: September 28 at 6 pm)

  This set of exercise is mostly taken from R for Data Science by Garrett Grolemund and Hadley Wickham.
```{r}
library(tidyverse)
library(nycflights13)
```
  

# Exercise 1

1.  Imagine you wanted to draw on a map the route each plane flies from
    its origin to its destination. What variables would you need? What tables
    would you need to combine?

    Answer: 

I would need `origin` and `dest` in `flights`. I would also need 'faa', which is the IATA code of the airports, `long` and `lat`from the `airports` dataset, joining them twice as both `origin` and `dest` will be corresponded with `faa`.


2.  We know that some days of the year are "special", and fewer people than
    usual fly on them. How might you represent that data as a data frame?
    What would be the primary keys of that table? How would it connect to the
    existing tables?

    Answer: 

I would create a dataset called `special days` with four columns, `year`, `month`, `day` and `festival`. I will join them with `year`, `month`, and `day` as keys, with the origin dataset.

# Exercise 2

1.  Add a surrogate key to `flights`.

    Answer: I will create an index for each flight as `Surr_Key`.

    ```{r}
    Surr_Key = 1:nrow(flights)
    flights <- cbind(Surr_Key,flights)
    ```

2.  Identify the keys in the following datasets

    Answer: 


    1.  `Lahman::Batting`,
    Answer: `playerID`, `yearID` and `stint`.

    ```{r,eval = FALSE}
    library(Lahman)
    Lahman::Batting %>%
      group_by(playerID, yearID, stint) %>%
      filter(n() > 1) %>%
      nrow()
    ```

    2.  `babynames::babynames`
    
    Answer: `year`, `sex` and `name`.

    ```{r, eval = FALSE}
    library(babynames)
    babynames %>%
      group_by(year, sex, name) %>%
      filter(n() > 1) %>%
      nrow()
    ```

    3.  `nasaweather::atmos`
    Answer: `lat`, `long`, `year` and `month`.

    ```{r, eval = FALSE}
    library(nasaweather)
    nasaweather::atmos %>%
      group_by(lat, long, year, month) %>%
      filter(n() > 1) %>%
      nrow()
    ```


3.  Draw a diagram illustrating the connections between the `Batting`,
    `Master`, and `Salaries` tables in the Lahman package.  
    (A diagram does not have to be a perfect picture. It can be tables 
    with some explanation, or it can be a scanned image of your sketch.)

    Answer: 
    
    So in `Master`, we have `playerID` as the primary key. We will link it with the `playerID` in `Salaries` and `Batting`. In Salaries, the primary key, as noted in the previous question is  `playerID`, `yearID` and `stint` abd for the `Salaries`, the primary ID is `yearID`, `teamID`, and `playerID`.o

# Exercise 3

1.  Compute the average arrival delay by destination, then join on the `airports`
    data frame so you can show the spatial distribution of delays. Here's an
    easy way to draw a map of the United States:

    ```{r, eval = FALSE}
    airports %>%
      semi_join(flights, c("faa" = "dest")) %>%
      ggplot(aes(lon, lat)) +
        borders("state") +
        geom_point() +
        coord_quickmap()
    ```

    (Don't worry if you don't understand what `semi_join()` does --- you'll
    learn about it next.)

    You might want to use the `colour` of the points to display
    the average delay for each airport.

    Answer: 

    ```{r}
  flights %>%
  group_by(dest) %>%
  summarise(delay = mean(arr_delay, na.rm = TRUE)) %>%
  inner_join(airports, by = c(dest = "faa")) %>%
  ggplot(aes(lon, lat, colour = delay)) +
  borders("state") +
  geom_point() +
  coord_quickmap()
    ```

2.  Add the location of the origin _and_ destination (i.e. the `lat` and `lon`)
    to `flights`.

    Answer: 

    ```{r}
    airport_locations <- airports %>%
      select(faa, lat, lon)
    flights <- flights %>%
  left_join(
    airport_locations,
    by = c("origin" = "faa")
  ) %>%
  left_join(
    airport_locations,
    by = c("dest" = "faa"))
    ```

3.  Is there a relationship between the age of a plane and its delays? 

    Answer: So we first create a variable age in `planes`

    ```{r}
    planes.age <- planes %>%
      mutate(age = 2013 - year) %>%
      select(tailnum, age) 
    flights %>%
      left_join(planes.age, by = "tailnum") %>%
      group_by(age) %>%
      filter(!is.na(dep_delay)) %>%
      summarise(delay = mean(dep_delay)) %>%
      ggplot(aes(x = age, y = delay)) +
      geom_col()
    ```
    
    So It does not seem to have a significant relationship between age and delay!

4.  What happened on June 13 2013? Display the spatial pattern of delays,
    and then use Google to cross-reference with the weather.

    ```{r, eval = FALSE, include = FALSE}
    worst <- filter(flights, !is.na(dep_time), month == 6, day == 13)
    worst %>%
      group_by(dest) %>%
      summarise(delay = mean(arr_delay), n = n()) %>%
      filter(n > 5) %>%
      inner_join(airports, by = c("dest" = "faa")) %>%
      ggplot(aes(lon, lat)) +
        borders("state") +
        geom_point(aes(size = n, colour = delay)) +
        coord_quickmap()
    ```

    Answer: So after googling that, I find out that there was storms all over the place. See what I googled below:

https://www.washingtonpost.com/news/capital-weather-gang/wp/2013/06/14/june-13-2013-severe-weather-hypestorm-or-the-real-deal/?utm_term=.6ce4dc1abd2e

    ```{r}
flights %>%
  filter(year == 2013, month == 6, day == 13) %>%
  group_by(dest) %>%
  summarise(delay = mean(arr_delay, na.rm = TRUE)) %>%
  inner_join(airports, by = c("dest" = "faa")) %>%
  ggplot(aes(y = lat, x = lon, size = delay, colour = delay)) +
  borders("state") +
  geom_point() +
  coord_quickmap()
    ```



# Exercise 4

1.  Filter flights to only show flights with planes that have flown at least 100
    flights.

    Answer: 

    ```{r}
old.plane <- flights %>%
      group_by(tailnum) %>%
      count() %>%
      filter(n >= 100)
  
flights %>%
  semi_join(old.plane, by = "tailnum")
    ```

2.  Combine `fueleconomy::vehicles` and `fueleconomy::common` to find only the
    records for the most common models.

    Answer: 

    ```{r}
library(fueleconomy)
most.common <- common %>% 
  arrange(desc(n)) %>%
  select(make, model) %>%
  head(1)
vehicles %>%
  semi_join(most.common, by = c("make", "model"))
    ```

3.  What does `anti_join(flights, airports, by = c("dest" = "faa"))` tell you?
    What does `anti_join(airports, flights, by = c("faa" = "dest"))` tell you?

    Answer: `anti_join(flights, airports, by = c("dest" = "faa"))` tells me that this filters all the flight that the destination is not a FAA listed airport (which will actually be very weird). `anti_join(airports, flights, by = c("faa" = "dest"))`tells me that this will provide a list of airports that does not have a flight from NYC in 2013.

4.  You might expect that there's an implicit relationship between plane
    and airline, because each plane is flown by a single airline. Confirm
    or reject this hypothesis using the tools you've learned above.

    Answer: So basically, you want the plane that are flown by multiple airlines. 

    ```{r}
multiple.airlines <- flights %>%
      filter(!is.na(tailnum)) %>%
      count(tailnum, carrier) %>%
      count(tailnum) %>%
      filter(nn > 1)

flights %>%
  semi_join(multiple.airlines, by = "tailnum") %>%
  select(tailnum,carrier) %>%
  distinct()
    ```

So there are seventeen of them. Okay, let's talk about the history of these plane. I did some research on the tailnum and I found that NxxxATs are Boeing 717s purchased by delta in 2013 from AirTran. So there is a change of operator. The rest, NXXXPQs were originally owned by Endeavor air which changed its IATA code from FL to EV, so there is no change of carrier involved. So there was no carrier change at all. So I believe the carrier may not tell a good story here.
# Exercise 5

1.  Given the corpus of common words in `stringr::words`, create regular
    expressions that find all words that:  
    
    (Put the regular expression after "Answer: " below. Feel free to experiment in the r code chunks. We will grade only the regular expression you put after "Answer: ")

    1. Start with "y".  
    Answer: "^y"


    1. End with "x"  
    Answer: '"x$"


    1. Are exactly three letters long. (Don't cheat by using `str_length()`!)  
    Answer: ^...$

    1. Have seven letters or more.

    Since this list is long, you might want to use the `match` argument to
    `str_view()` to show only the matching or non-matching words.  
    Answer: "......."


2.  Create regular expressions to find all words that:  
  (Put the regular expression after "Answer: " below. Feel free to experiment in the r code chunks. We will grade only the regular expression you put after "Answer: ")


    1. Start with a vowel.  
    Answer:"^[aeiou]"


    1. That only contain consonants. (Hint: thinking about matching
       "not"-vowels.)  
    Answer: "^[^aeiou]+$"

    1. End with `ed`, but not with `eed`.  
    Answer: "^ed$|[^e]ed$"


    1. End with `ing` or `ise`.  
    Answer:"i(ng|se)$"

3.  Create regular expressions to find all words that:  
  (Put the regular expression after "Answer: " below. Feel free to experiment in the r code chunks. We will grade only the regular expression you put after "Answer: ")


    1. Start with three consonants.  
    Answer:"^[^aeiou]{3}"


    1. Have three or more vowels in a row.  
    Answer:"[aeiou]{3,}"


    1. Have two or more vowel-consonant pairs in a row.  
    Answer:"([aeiou][^aeiou]){2,}".


4.  From the Harvard sentences data, extract:

    1. The first word from each sentence.  
    (Assign this list of words to a variable called "first.words")  
```{r}
first.words <- str_extract(sentences, "[a-zA-Z]+")
```

    1. All words ending in `ing`.  
    (Assign this list of words to a variable called "ing.words")
```{r}
ing.words <- c()
for (i in sentences) {
  ing <- cbind(ing.words,str_extract(i,"\\b[A-Za-z]+ing\\b"))
}
ing.words <- ing.words[!is.na(ing.words)]
```

    1. All plurals.  
    (Assign this list of words to a variable called "plural.words")
```{r}
plural.words <- unique(unlist(str_extract_all(sentences, "\\b[A-Za-z]{2,}s\\b"))) 
```

5.   Switch the first and last letters in `words`.  
    (Note `words` here refer to the the corpus of common words in `stringr::words`. Assign this newly created corpus after switching to a variable called `words.switched`)
    
```{r}
words.switched <- str_replace_all(words, "^([A-Za-z])(.*)([a-z])$", "\\3\\2\\1")
```

6.  Split up a string like `"apples, pears, and bananas"` into individual components.  
    (Assign this vector of strings to a variable called `fruits`. Make sure to convert this into a vector by doing "%>% .[[1]]")
```{r}
fruits <- str_split("apples, pears, and bananas", ", +(and +)?")[[1]]
```
